{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96547f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haris\\AppData\\Local\\Temp\\ipykernel_7132\\1966572566.py:3: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(r\"../dataset/emi_prediction_dataset.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"../dataset/emi_prediction_dataset.csv\")\n",
    "\n",
    "edu_categories = ['High School', 'Graduate', 'Post Graduate', 'Professional']\n",
    "company_categories = ['Startup', 'Small', 'Mid-size', 'Large Indian', 'MNC']\n",
    "house_type_categories = [\"Rented\", \"Family\", \"Own\"]\n",
    "emi_eligibility_categories = ['Not_Eligible', 'High_Risk', 'Eligible']\n",
    "\n",
    "data['credit_score'] = pd.to_numeric(data['credit_score'], errors='coerce')\n",
    "data = data[(data['credit_score'] <= 900) & data['credit_score'].notna()].reset_index(drop=True)\n",
    "\n",
    "data = data[~((data[\"house_type\"] == \"Rented\") & data[\"monthly_rent\"].isna())].reset_index(drop=True)\n",
    "\n",
    "data['age'] = (\n",
    "    data['age'].astype(str)\n",
    "    .str.strip()                              # remove spaces\n",
    "    .str.replace(r'[^0-9.]', '', regex=True)  # keep only digits and dots\n",
    "    .str.replace(r'(\\.\\d*)\\..*', r'\\1', regex=True)  # keep only first decimal part\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "data['gender'] = data['gender'].astype(str).str.strip().str.lower()\n",
    "data['gender'] = data['gender'].replace({'^m$': 'male', '^f$': 'female'}, regex=True)\n",
    "data['gender'] = data['gender'].replace(r'^\\s*$', pd.NA, regex=True)\n",
    "data['gender'] = data['gender'].map({'male': 0, 'female': 1})\n",
    "\n",
    "data['marital_status'] = data['marital_status'].astype(str).str.strip().str.lower()\n",
    "data['marital_status'] = data['marital_status'].replace(r'^\\s*$', pd.NA, regex=True)\n",
    "data['marital_status'] = data['marital_status'].map({'single': 0, 'married': 1})\n",
    "\n",
    "data[\"education\"] = pd.Series(\n",
    "    pd.Categorical(data[\"education\"], categories=edu_categories, ordered=True).codes\n",
    ").replace({-1: pd.NA})\n",
    "\n",
    "data[\"monthly_salary\"] = (\n",
    "    data['monthly_salary'].astype(str)\n",
    "    .str.strip()                              # remove spaces\n",
    "    .str.replace(r'[^0-9.]', '', regex=True)  # keep only digits and dots\n",
    "    .str.replace(r'(\\.\\d*)\\..*', r'\\1', regex=True)  # keep only first decimal part\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# data[\"monthly_salary\"] = pd.to_numeric(data[\"monthly_salary\"], errors='coerce')\n",
    "\n",
    "# data[\"employment_type\"] = pd.get_dummies(data[\"employment_type\"]).add_suffix(\"_job\")\n",
    "\n",
    "data = pd.get_dummies(data, columns=[\"employment_type\"], dtype=\"int\") \n",
    "\n",
    "\n",
    "data['company_type'] = pd.Series(\n",
    "    pd.Categorical(data[\"company_type\"], categories=company_categories, ordered=True).codes\n",
    ").replace({-1: pd.NA})\n",
    "\n",
    "\n",
    "data['house_type'] = pd.Series(\n",
    "    pd.Categorical(data[\"house_type\"], categories=house_type_categories, ordered=True).codes\n",
    ").replace({-1: pd.NA})\n",
    "\n",
    "data[\"bank_balance\"] = (\n",
    "    data['bank_balance'].astype(str)\n",
    "    .str.strip()                              # remove spaces\n",
    "    .str.replace(r'[^0-9.]', '', regex=True)  # keep only digits and dots\n",
    "    .str.replace(r'(\\.\\d*)\\..*', r'\\1', regex=True)  # keep only first decimal part\n",
    ")\n",
    "data[\"bank_balance\"] = pd.to_numeric(data[\"bank_balance\"], errors=\"coerce\")\n",
    "\n",
    "data['existing_loans'] = data['existing_loans'].astype(str).str.strip().str.lower()\n",
    "data['existing_loans'] = data['existing_loans'].replace(r'^\\s*$', pd.NA, regex=True)\n",
    "data['existing_loans'] = data['existing_loans'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "data[\"emi_eligibility\"] = pd.Series(\n",
    "    pd.Categorical(data[\"emi_eligibility\"], categories=emi_eligibility_categories, ordered=True).codes\n",
    ").replace({-1: pd.NA})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec6ecc24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education</th>\n",
       "      <th>monthly_salary</th>\n",
       "      <th>years_of_employment</th>\n",
       "      <th>company_type</th>\n",
       "      <th>house_type</th>\n",
       "      <th>monthly_rent</th>\n",
       "      <th>family_size</th>\n",
       "      <th>...</th>\n",
       "      <th>bank_balance</th>\n",
       "      <th>emergency_fund</th>\n",
       "      <th>emi_scenario</th>\n",
       "      <th>requested_amount</th>\n",
       "      <th>requested_tenure</th>\n",
       "      <th>emi_eligibility</th>\n",
       "      <th>max_monthly_emi</th>\n",
       "      <th>employment_type_Government</th>\n",
       "      <th>employment_type_Private</th>\n",
       "      <th>employment_type_Self-employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>82600.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>Rented</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>303200.0</td>\n",
       "      <td>70200.0</td>\n",
       "      <td>Personal Loan EMI</td>\n",
       "      <td>850000.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Not_Eligible</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21500.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Family</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>92500.0</td>\n",
       "      <td>26900.0</td>\n",
       "      <td>E-commerce Shopping EMI</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>Not_Eligible</td>\n",
       "      <td>700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>86100.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "      <td>Own</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>672100.0</td>\n",
       "      <td>324200.0</td>\n",
       "      <td>Education EMI</td>\n",
       "      <td>306000.0</td>\n",
       "      <td>16</td>\n",
       "      <td>Eligible</td>\n",
       "      <td>27775.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66800.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "      <td>Own</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>440900.0</td>\n",
       "      <td>178100.0</td>\n",
       "      <td>Vehicle EMI</td>\n",
       "      <td>304000.0</td>\n",
       "      <td>83</td>\n",
       "      <td>Eligible</td>\n",
       "      <td>16170.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>57300.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2</td>\n",
       "      <td>Family</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>97300.0</td>\n",
       "      <td>28200.0</td>\n",
       "      <td>Home Appliances EMI</td>\n",
       "      <td>252000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>Not_Eligible</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  gender  marital_status education  monthly_salary  \\\n",
       "0  38.0       1               1         3         82600.0   \n",
       "1  38.0       1               1         1         21500.0   \n",
       "2  38.0       0               1         3         86100.0   \n",
       "3  58.0       1               1         0         66800.0   \n",
       "4  48.0       1               1         3         57300.0   \n",
       "\n",
       "   years_of_employment  company_type house_type  monthly_rent  family_size  \\\n",
       "0                  0.9             2     Rented       20000.0            3   \n",
       "1                  7.0             4     Family           0.0            2   \n",
       "2                  5.8             0        Own           0.0            4   \n",
       "3                  2.2             2        Own           0.0            5   \n",
       "4                  3.4             2     Family           0.0            4   \n",
       "\n",
       "   ...  bank_balance  emergency_fund             emi_scenario  \\\n",
       "0  ...      303200.0         70200.0        Personal Loan EMI   \n",
       "1  ...       92500.0         26900.0  E-commerce Shopping EMI   \n",
       "2  ...      672100.0        324200.0            Education EMI   \n",
       "3  ...      440900.0        178100.0              Vehicle EMI   \n",
       "4  ...       97300.0         28200.0      Home Appliances EMI   \n",
       "\n",
       "   requested_amount  requested_tenure  emi_eligibility  max_monthly_emi  \\\n",
       "0          850000.0                15     Not_Eligible            500.0   \n",
       "1          128000.0                19     Not_Eligible            700.0   \n",
       "2          306000.0                16         Eligible          27775.0   \n",
       "3          304000.0                83         Eligible          16170.0   \n",
       "4          252000.0                 7     Not_Eligible            500.0   \n",
       "\n",
       "   employment_type_Government  employment_type_Private  \\\n",
       "0                           0                        1   \n",
       "1                           0                        1   \n",
       "2                           0                        1   \n",
       "3                           0                        1   \n",
       "4                           0                        1   \n",
       "\n",
       "   employment_type_Self-employed  \n",
       "0                              0  \n",
       "1                              0  \n",
       "2                              0  \n",
       "3                              0  \n",
       "4                              0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "caa97529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                                 0\n",
       "gender                              0\n",
       "marital_status                      0\n",
       "education                        2370\n",
       "monthly_salary                      0\n",
       "years_of_employment                 0\n",
       "company_type                        0\n",
       "house_type                          0\n",
       "monthly_rent                     1471\n",
       "family_size                         0\n",
       "dependents                          0\n",
       "school_fees                         0\n",
       "college_fees                        0\n",
       "travel_expenses                     0\n",
       "groceries_utilities                 0\n",
       "other_monthly_expenses              0\n",
       "existing_loans                      0\n",
       "current_emi_amount                  0\n",
       "credit_score                        0\n",
       "bank_balance                     2384\n",
       "emergency_fund                   2321\n",
       "emi_scenario                        0\n",
       "requested_amount                    0\n",
       "requested_tenure                    0\n",
       "emi_eligibility                     0\n",
       "max_monthly_emi                     0\n",
       "employment_type_Government          0\n",
       "employment_type_Private             0\n",
       "employment_type_Self-employed       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7ebdea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398245"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20baa184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = data.drop(columns=[\"emi_eligibility\", \"max_monthly_emi\"])\n",
    "emi_eligibility = data[\"emi_eligibility\"]\n",
    "max_monthly_emi = data[\"max_monthly_emi\"]\n",
    "\n",
    "# classification model train_test_split for emi eligibility\n",
    "x_train_classification, x_test_classification, y_train_classification, y_test_classification = train_test_split(x, emi_eligibility, test_size=0.2, random_state=42)\n",
    "\n",
    "# regression model train test split for max monthly emi\n",
    "x_train_regression, x_test_regression, y_train_regression, y_test_regression = train_test_split(x, max_monthly_emi, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138df3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "preprocess_train_mlflow.py\n",
    "Usage:\n",
    "    python preprocess_train_mlflow.py [--data PATH] [--quick] [--outdir OUTDIR]\n",
    "\n",
    "This script:\n",
    " - Loads CSV dataset\n",
    " - Cleans data, imputes, adds derived features\n",
    " - Runs EDA summary outputs (value counts, missingness, correlations)\n",
    " - Builds preprocessing pipeline\n",
    " - Trains 3 classification models and 3 regression models\n",
    " - Logs experiments to MLflow (local by default)\n",
    " - Saves preprocessor and best models to OUTDIR\n",
    "\"\"\"\n",
    "\n",
    "import argparse, os, sys, json\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import mlflow, mlflow.sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def load_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "def basic_clean(df):\n",
    "    # strip strings, coerce numeric columns\n",
    "    for c in df.select_dtypes(include=[\"object\",\"category\"]).columns:\n",
    "        df[c] = df[c].astype(str).str.strip()\n",
    "    numeric_guess = [\"monthly_salary\",\"current_emi_amount\",\"requested_amount\",\"bank_balance\",\"emergency_fund\",\n",
    "                     \"monthly_rent\",\"school_fees\",\"college_fees\",\"travel_expenses\",\"groceries_utilities\",\"other_monthly_expenses\",\"credit_score\"]\n",
    "    for c in numeric_guess:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def add_derived(df):\n",
    "    if {\"monthly_salary\",\"current_emi_amount\"}.issubset(df.columns):\n",
    "        df[\"debt_to_income\"] = df[\"current_emi_amount\"] / df[\"monthly_salary\"].replace(0, np.nan)\n",
    "    if {\"monthly_salary\",\"other_monthly_expenses\"}.issubset(df.columns):\n",
    "        df[\"expense_to_income\"] = df[\"other_monthly_expenses\"] / df[\"monthly_salary\"].replace(0, np.nan)\n",
    "    if {\"monthly_salary\",\"requested_amount\",\"requested_tenure\"}.issubset(df.columns):\n",
    "        df[\"requested_monthly_no_interest\"] = df[\"requested_amount\"] / df[\"requested_tenure\"].replace(0, np.nan)\n",
    "        df[\"affordability_ratio\"] = df[\"requested_monthly_no_interest\"] / df[\"monthly_salary\"].replace(0, np.nan)\n",
    "    return df\n",
    "\n",
    "def build_preprocessor(df, max_ohe_cardinality=50):\n",
    "    numeric_features = df.select_dtypes(include=[\"int64\",\"float64\"]).columns.tolist()\n",
    "    numeric_features = [c for c in numeric_features if c not in [\"max_monthly_emi\"]]\n",
    "    cat_features = [c for c in df.select_dtypes(include=[\"object\",\"category\"]).columns.tolist() if c not in [\"emi_eligibility\"]]\n",
    "\n",
    "    # collapse high-cardinality categories to top-K + OTHER\n",
    "    for c in cat_features:\n",
    "        if df[c].nunique() > max_ohe_cardinality:\n",
    "            top = df[c].value_counts().index[:max_ohe_cardinality].astype(str)\n",
    "            df[c] = df[c].apply(lambda x: x if x in top else \"OTHER\").astype(str)\n",
    "\n",
    "    num_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())])\n",
    "    cat_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")), (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))])\n",
    "    preprocessor = ColumnTransformer([(\"num\", num_pipe, numeric_features), (\"cat\", cat_pipe, cat_features)], remainder=\"drop\")\n",
    "    return preprocessor, numeric_features, cat_features\n",
    "\n",
    "def train_and_evaluate(X_train, X_test, y_train_cl, y_test_cl, y_train_rg, y_test_rg, preprocessor, outdir, quick=False):\n",
    "    # Transform\n",
    "    preprocessor.fit(X_train)\n",
    "    X_train_t = preprocessor.transform(X_train)\n",
    "    X_test_t = preprocessor.transform(X_test)\n",
    "\n",
    "    # Classification models\n",
    "    cl_models = {\n",
    "        \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=100 if not quick else 30, n_jobs=-1, random_state=42),\n",
    "        \"XGBoost\": None\n",
    "    }\n",
    "    # Try to use XGBoost if available\n",
    "    try:\n",
    "        import xgboost as xgb\n",
    "        from xgboost import XGBClassifier, XGBRegressor\n",
    "        cl_models[\"XGBoost\"] = XGBClassifier(n_estimators=200 if not quick else 50, use_label_encoder=False, eval_metric=\"mlogloss\", tree_method=\"hist\")\n",
    "        rg_xgb_present = True\n",
    "    except Exception:\n",
    "        cl_models.pop(\"XGBoost\", None)\n",
    "        rg_xgb_present = False\n",
    "\n",
    "    rg_models = {\n",
    "        \"LinearRegression\": LinearRegression(),\n",
    "        \"RandomForestRegressor\": RandomForestRegressor(n_estimators=100 if not quick else 30, random_state=42, n_jobs=-1),\n",
    "    }\n",
    "    if rg_xgb_present:\n",
    "        rg_models[\"XGBoostRegressor\"] = XGBRegressor(n_estimators=200 if not quick else 50)\n",
    "\n",
    "    # MLflow experiment\n",
    "    mlflow.set_experiment(\"EMI_eligibility_and_max_emi\")\n",
    "    best_cl = (None, -1.0)  # (name, accuracy)\n",
    "    best_rg = (None, 1e12)  # (name, rmse)\n",
    "    for name, model in cl_models.items():\n",
    "        with mlflow.start_run(run_name=f\"cl_{name}\"):\n",
    "            mlflow.log_param(\"model\", name)\n",
    "            model.fit(X_train_t, y_train_cl)\n",
    "            preds = model.predict(X_test_t)\n",
    "            acc = accuracy_score(y_test_cl, preds)\n",
    "            mlflow.log_metric(\"accuracy\", float(acc))\n",
    "            # save model artifact\n",
    "            mlflow.sklearn.log_model(model, artifact_path=f\"models/{name}\")\n",
    "            if acc > best_cl[1]:\n",
    "                best_cl = (name, acc)\n",
    "    for name, model in rg_models.items():\n",
    "        with mlflow.start_run(run_name=f\"rg_{name}\"):\n",
    "            mlflow.log_param(\"model\", name)\n",
    "            model.fit(X_train_t, y_train_rg)\n",
    "            preds = model.predict(X_test_t)\n",
    "            rmse = mean_squared_error(y_test_rg, preds, squared=False)\n",
    "            mae = mean_absolute_error(y_test_rg, preds)\n",
    "            r2 = r2_score(y_test_rg, preds)\n",
    "            mlflow.log_metric(\"rmse\", float(rmse))\n",
    "            mlflow.log_metric(\"mae\", float(mae))\n",
    "            mlflow.log_metric(\"r2\", float(r2))\n",
    "            mlflow.sklearn.log_model(model, artifact_path=f\"models/{name}\")\n",
    "            if rmse < best_rg[1]:\n",
    "                best_rg = (name, rmse)\n",
    "\n",
    "    # Save preprocessor & best models locally\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    joblib.dump(preprocessor, os.path.join(outdir, \"preprocessor.joblib\"))\n",
    "\n",
    "    # For reproducibility, re-fit best models on full training set and save\n",
    "    print(\"Best classification model:\", best_cl)\n",
    "    print(\"Best regression model:\", best_rg)\n",
    "    return\n",
    "\n",
    "def main(args):\n",
    "    df = load_data(args.data)\n",
    "    df = basic_clean(df)\n",
    "    df = add_derived(df)\n",
    "    # drop rows missing targets\n",
    "    df = df.dropna(subset=[\"emi_eligibility\",\"max_monthly_emi\"])\n",
    "    print(\"Data shape after cleaning:\", df.shape)\n",
    "\n",
    "    preprocessor, numeric_features, cat_features = build_preprocessor(df)\n",
    "    # quick mode: small stratified sample\n",
    "    if args.quick:\n",
    "        train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"emi_eligibility\"], random_state=42)\n",
    "        # sample per class\n",
    "        train_df = train_df.groupby(\"emi_eligibility\", group_keys=False).apply(lambda x: x.sample(n=min(len(x), 2000), random_state=42))\n",
    "        test_df = test_df.groupby(\"emi_eligibility\", group_keys=False).apply(lambda x: x.sample(n=min(len(x), 500), random_state=42))\n",
    "    else:\n",
    "        train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"emi_eligibility\"], random_state=42)\n",
    "\n",
    "    X_train = train_df[numeric_features + cat_features]\n",
    "    X_test = test_df[numeric_features + cat_features]\n",
    "    y_train_cl = train_df[\"emi_eligibility\"]\n",
    "    y_test_cl = test_df[\"emi_eligibility\"]\n",
    "    y_train_rg = train_df[\"max_monthly_emi\"].astype(float)\n",
    "    y_test_rg = test_df[\"max_monthly_emi\"].astype(float)\n",
    "\n",
    "    train_and_evaluate(X_train, X_test, y_train_cl, y_test_cl, y_train_rg, y_test_rg, preprocessor, args.outdir, quick=args.quick)\n",
    "    print(\"Done.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", default=\"/mnt/data/emi_prediction_dataset.csv\", help=\"path to CSV\")\n",
    "    parser.add_argument(\"--outdir\", default=\"./artifacts\", help=\"where to save preprocessor and models\")\n",
    "    parser.add_argument(\"--quick\", action=\"store_true\", help=\"use small sample for fast run\")\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cbca834",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier, RandomForestRegressor\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier, XGBRegressor\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\mlflow\\__init__.py:44\u001b[0m\n\u001b[0;32m     41\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mmismatch\u001b[38;5;241m.\u001b[39m_check_version_mismatch()\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m IS_TRACING_SDK_ONLY:\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     45\u001b[0m         artifacts,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     46\u001b[0m         client,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     47\u001b[0m         config,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     48\u001b[0m         data,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     49\u001b[0m         exceptions,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     50\u001b[0m         genai,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     51\u001b[0m         models,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     52\u001b[0m         projects,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     53\u001b[0m         tracking,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     )\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tracing  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvironment_variables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MLFLOW_CONFIGURE_LOGGING\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\mlflow\\artifacts\\__init__.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtempfile\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mentities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_info\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileInfo\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MlflowException\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatabricks_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BAD_REQUEST, INVALID_PARAMETER_VALUE\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\mlflow\\entities\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe ``mlflow.entities`` module defines entities returned by the MLflow\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m`REST API <../rest-api.html>`_.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mentities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massessment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     Assessment,\n\u001b[0;32m      8\u001b[0m     AssessmentError,\n\u001b[0;32m      9\u001b[0m     AssessmentSource,\n\u001b[0;32m     10\u001b[0m     AssessmentSourceType,\n\u001b[0;32m     11\u001b[0m     Expectation,\n\u001b[0;32m     12\u001b[0m     Feedback,\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mentities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mentities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_input\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetInput\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\mlflow\\entities\\assessment.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massessments_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Expectation \u001b[38;5;28;01mas\u001b[39;00m ProtoExpectation\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massessments_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Feedback \u001b[38;5;28;01mas\u001b[39;00m ProtoFeedback\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannotations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_stacktrace\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto_json_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m proto_timestamp_to_milliseconds\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\mlflow\\utils\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m islice\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version_info\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IS_PYDANTIC_V2_OR_NEWER  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     12\u001b[0m PYTHON_VERSION \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion_info\u001b[38;5;241m.\u001b[39mmajor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion_info\u001b[38;5;241m.\u001b[39mminor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion_info\u001b[38;5;241m.\u001b[39mmicro\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m _logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\mlflow\\utils\\pydantic_utils.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[0;32m      7\u001b[0m IS_PYDANTIC_V2_OR_NEWER \u001b[38;5;241m=\u001b[39m Version(pydantic\u001b[38;5;241m.\u001b[39mVERSION)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfield_validator\u001b[39m(field: \u001b[38;5;28mstr\u001b[39m, mode: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbefore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pydantic\\__init__.py:435\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 435\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpackage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, attr_name)\n\u001b[0;32m    437\u001b[0m     g \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2288.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pydantic\\main.py:36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Self, TypeAlias, Unpack\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PydanticDeprecatedSince20, PydanticDeprecatedSince211\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     37\u001b[0m     _config,\n\u001b[0;32m     38\u001b[0m     _decorators,\n\u001b[0;32m     39\u001b[0m     _fields,\n\u001b[0;32m     40\u001b[0m     _forward_ref,\n\u001b[0;32m     41\u001b[0m     _generics,\n\u001b[0;32m     42\u001b[0m     _mock_val_ser,\n\u001b[0;32m     43\u001b[0m     _model_construction,\n\u001b[0;32m     44\u001b[0m     _namespace_utils,\n\u001b[0;32m     45\u001b[0m     _repr,\n\u001b[0;32m     46\u001b[0m     _typing_extra,\n\u001b[0;32m     47\u001b[0m     _utils,\n\u001b[0;32m     48\u001b[0m )\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_migration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getattr_migration\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maliases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AliasChoices, AliasPath\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pydantic\\_internal\\_model_construction.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecoratorInfos, PydanticDescriptorProxy, get_attribute_from_bases, unwrap_wrapped_function\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fields\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collect_model_fields, is_valid_field_name, is_valid_privateattr_name\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_generate_schema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GenerateSchema, InvalidSchemaError\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_generics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PydanticGenericMetadata, get_model_typevars_map\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_import_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m import_cached_base_model, import_cached_field_info\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pydantic\\_internal\\_generate_schema.py:59\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_inspection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintrospection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnnotationSource, get_literal_values, is_union_origin\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maliases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AliasChoices, AliasGenerator, AliasPath\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannotated_handlers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GetCoreSchemaHandler, GetJsonSchemaHandler\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfigDict, JsonDict, JsonEncoder, JsonSchemaExtraCallable\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PydanticSchemaGenerationError, PydanticUndefinedAnnotation, PydanticUserError\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1091\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1190\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    mean_absolute_error, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ============ Step 1: Data Loading & Preprocessing ============\n",
    "file_path = \"../dataset/emi_prediction_dataset.csv\"  # change if needed\n",
    "data = pd.read_csv(file_path)\n",
    "print(f\"Loaded dataset shape: {data.shape}\")\n",
    "\n",
    "# Drop duplicates & handle missing\n",
    "data = data.drop_duplicates()\n",
    "print(f\"After cleaning: {data.shape}\")\n",
    "\n",
    "edu_categories = ['High School', 'Graduate', 'Post Graduate', 'Professional']\n",
    "company_categories = ['Startup', 'Small', 'Mid-size', 'Large Indian', 'MNC']\n",
    "house_type_categories = [\"Rented\", \"Family\", \"Own\"]\n",
    "emi_eligibility_categories = ['Not_Eligible', 'High_Risk', 'Eligible']\n",
    "\n",
    "data['credit_score'] = pd.to_numeric(data['credit_score'], errors='coerce')\n",
    "data = data[(data['credit_score'] <= 900) & data['credit_score'].notna()].reset_index(drop=True)\n",
    "\n",
    "data = data[~((data[\"house_type\"] == \"Rented\") & data[\"monthly_rent\"].isna())].reset_index(drop=True)\n",
    "\n",
    "data['age'] = (\n",
    "    data['age'].astype(str)\n",
    "    .str.strip()                              # remove spaces\n",
    "    .str.replace(r'[^0-9.]', '', regex=True)  # keep only digits and dots\n",
    "    .str.replace(r'(\\.\\d*)\\..*', r'\\1', regex=True)  # keep only first decimal part\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "data['gender'] = data['gender'].astype(str).str.strip().str.lower()\n",
    "data['gender'] = data['gender'].replace({'^m$': 'male', '^f$': 'female'}, regex=True)\n",
    "data['gender'] = data['gender'].replace(r'^\\s*$', pd.NA, regex=True)\n",
    "data['gender'] = data['gender'].map({'male': 0, 'female': 1})\n",
    "\n",
    "data['marital_status'] = data['marital_status'].astype(str).str.strip().str.lower()\n",
    "data['marital_status'] = data['marital_status'].replace(r'^\\s*$', pd.NA, regex=True)\n",
    "data['marital_status'] = data['marital_status'].map({'single': 0, 'married': 1})\n",
    "\n",
    "data[\"education\"] = pd.Series(\n",
    "    pd.Categorical(data[\"education\"], categories=edu_categories, ordered=True).codes\n",
    ").replace({-1: pd.NA})\n",
    "\n",
    "data[\"monthly_salary\"] = (\n",
    "    data['monthly_salary'].astype(str)\n",
    "    .str.strip()                              # remove spaces\n",
    "    .str.replace(r'[^0-9.]', '', regex=True)  # keep only digits and dots\n",
    "    .str.replace(r'(\\.\\d*)\\..*', r'\\1', regex=True)  # keep only first decimal part\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# data[\"monthly_salary\"] = pd.to_numeric(data[\"monthly_salary\"], errors='coerce')\n",
    "\n",
    "# data[\"employment_type\"] = pd.get_dummies(data[\"employment_type\"]).add_suffix(\"_job\")\n",
    "\n",
    "data = pd.get_dummies(data, columns=[\"employment_type\"], dtype=\"int\") \n",
    "\n",
    "\n",
    "data['company_type'] = pd.Series(\n",
    "    pd.Categorical(data[\"company_type\"], categories=company_categories, ordered=True).codes\n",
    ").replace({-1: pd.NA})\n",
    "\n",
    "\n",
    "data['house_type'] = pd.Series(\n",
    "    pd.Categorical(data[\"house_type\"], categories=house_type_categories, ordered=True).codes\n",
    ").replace({-1: pd.NA})\n",
    "\n",
    "data[\"bank_balance\"] = (\n",
    "    data['bank_balance'].astype(str)\n",
    "    .str.strip()                              # remove spaces\n",
    "    .str.replace(r'[^0-9.]', '', regex=True)  # keep only digits and dots\n",
    "    .str.replace(r'(\\.\\d*)\\..*', r'\\1', regex=True)  # keep only first decimal part\n",
    ")\n",
    "data[\"bank_balance\"] = pd.to_numeric(data[\"bank_balance\"], errors=\"coerce\")\n",
    "\n",
    "data['existing_loans'] = data['existing_loans'].astype(str).str.strip().str.lower()\n",
    "data['existing_loans'] = data['existing_loans'].replace(r'^\\s*$', pd.NA, regex=True)\n",
    "data['existing_loans'] = data['existing_loans'].map({'no': 0, 'yes': 1})\n",
    "\n",
    "data[\"emi_eligibility\"] = pd.Series(\n",
    "    pd.Categorical(data[\"emi_eligibility\"], categories=emi_eligibility_categories, ordered=True).codes\n",
    ").replace({-1: pd.NA})\n",
    "\n",
    "# # Encode categorical variables\n",
    "# cat_cols = data.select_dtypes(include=['object']).columns\n",
    "# for col in cat_cols:\n",
    "#     data[col] = LabelEncoder().fit_transform(data[col].astype(str))\n",
    "\n",
    "# Split targets\n",
    "X = data.drop(['emi_eligibility', 'max_monthly_emi'], axis=1)\n",
    "y_class = data['emi_eligibility']\n",
    "y_reg = data['max_monthly_emi']\n",
    "\n",
    "# Split train/test/validation\n",
    "X_train, X_temp, y_class_train, y_class_temp, y_reg_train, y_reg_temp = train_test_split(\n",
    "    X, y_class, y_reg, test_size=0.3, random_state=42, stratify=y_class\n",
    ")\n",
    "X_val, X_test, y_class_val, y_class_test, y_reg_val, y_reg_test = train_test_split(\n",
    "    X_temp, y_class_temp, y_reg_temp, test_size=0.5, random_state=42, stratify=y_class_temp\n",
    ")\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ============ Step 2: MLflow Setup ============\n",
    "mlflow.set_experiment(\"EMI_Prediction_Experiment\")\n",
    "\n",
    "def log_classification_results(model_name, model, X_train, y_train, X_test, y_test):\n",
    "    mlflow.start_run(run_name=f\"{model_name}_classification\")\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, preds),\n",
    "        \"precision\": precision_score(y_test, preds, average='weighted'),\n",
    "        \"recall\": recall_score(y_test, preds, average='weighted'),\n",
    "        \"f1_score\": f1_score(y_test, preds, average='weighted')\n",
    "    }\n",
    "    mlflow.log_params(model.get_params())\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(model, model_name)\n",
    "    mlflow.end_run()\n",
    "    \n",
    "    print(f\"\\n[{model_name} Classification Results]\")\n",
    "    for k,v in metrics.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "def log_regression_results(model_name, model, X_train, y_train, X_test, y_test):\n",
    "    mlflow.start_run(run_name=f\"{model_name}_regression\")\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        \"RMSE\": np.sqrt(mean_squared_error(y_test, preds)),\n",
    "        \"MAE\": mean_absolute_error(y_test, preds),\n",
    "        \"R2\": r2_score(y_test, preds),\n",
    "        \"MAPE\": np.mean(np.abs((y_test - preds) / y_test)) * 100\n",
    "    }\n",
    "    mlflow.log_params(model.get_params())\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.sklearn.log_model(model, model_name)\n",
    "    mlflow.end_run()\n",
    "    \n",
    "    print(f\"\\n[{model_name} Regression Results]\")\n",
    "    for k,v in metrics.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# ============ Step 3: Classification Models ============\n",
    "print(\"\\n=== Classification Models ===\")\n",
    "log_classification_results(\"LogisticRegression\", LogisticRegression(max_iter=1000), X_train, y_class_train, X_test, y_class_test)\n",
    "log_classification_results(\"RandomForestClassifier\", RandomForestClassifier(n_estimators=100, random_state=42), X_train, y_class_train, X_test, y_class_test)\n",
    "log_classification_results(\"XGBoostClassifier\", XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42), X_train, y_class_train, X_test, y_class_test)\n",
    "\n",
    "# ============ Step 4: Regression Models ============\n",
    "print(\"\\n=== Regression Models ===\")\n",
    "log_regression_results(\"LinearRegression\", LinearRegression(), X_train, y_reg_train, X_test, y_reg_test)\n",
    "log_regression_results(\"RandomForestRegressor\", RandomForestRegressor(n_estimators=100, random_state=42), X_train, y_reg_train, X_test, y_reg_test)\n",
    "log_regression_results(\"XGBoostRegressor\", XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42), X_train, y_reg_train, X_test, y_reg_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689921e2",
   "metadata": {},
   "source": [
    "# complete code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48b783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emi_full_pipeline_allinone.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import streamlit as st\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import f1_score, r2_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ================== 1ï¸âƒ£ Data Loading & Cleaning ==================\n",
    "def load_and_clean_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data.drop_duplicates()\n",
    "    # Categories\n",
    "    edu_categories = ['High School', 'Graduate', 'Post Graduate', 'Professional']\n",
    "    company_categories = ['Startup', 'Small', 'Mid-size', 'Large Indian', 'MNC']\n",
    "    house_type_categories = [\"Rented\", \"Family\", \"Own\"]\n",
    "    emi_eligibility_categories = ['Not_Eligible', 'High_Risk', 'Eligible']\n",
    "    # Cleaning numeric columns\n",
    "    data['credit_score'] = pd.to_numeric(data['credit_score'], errors='coerce')\n",
    "    data = data[(data['credit_score'] <= 900) & data['credit_score'].notna()].reset_index(drop=True)\n",
    "    data = data[~((data[\"house_type\"] == \"Rented\") & data[\"monthly_rent\"].isna())].reset_index(drop=True)\n",
    "    data['age'] = (data['age'].astype(str).str.strip().str.replace(r'[^0-9.]', '', regex=True)\n",
    "                   .str.replace(r'(\\.\\d*)\\..*', r'\\1', regex=True).astype(float))\n",
    "    data['gender'] = data['gender'].astype(str).str.strip().str.lower()\n",
    "    data['gender'] = data['gender'].replace({'^m$': 'male', '^f$': 'female'}, regex=True)\n",
    "    data['gender'] = data['gender'].replace(r'^\\s*$', pd.NA, regex=True).map({'male': 0, 'female': 1})\n",
    "    data['marital_status'] = data['marital_status'].astype(str).str.strip().str.lower()\n",
    "    data['marital_status'] = data['marital_status'].replace(r'^\\s*$', pd.NA, regex=True).map({'single':0,'married':1})\n",
    "    data[\"education\"] = pd.Series(pd.Categorical(data[\"education\"], categories=edu_categories, ordered=True).codes).replace({-1: pd.NA})\n",
    "    data[\"monthly_salary\"] = (data['monthly_salary'].astype(str).str.strip().str.replace(r'[^0-9.]','',regex=True)\n",
    "                              .str.replace(r'(\\.\\d*)\\..*', r'\\1', regex=True).astype(float))\n",
    "    data = pd.get_dummies(data, columns=[\"employment_type\"], dtype=\"int\")\n",
    "    data['company_type'] = pd.Series(pd.Categorical(data[\"company_type\"], categories=company_categories, ordered=True).codes).replace({-1: pd.NA})\n",
    "    data['house_type'] = pd.Series(pd.Categorical(data[\"house_type\"], categories=house_type_categories, ordered=True).codes).replace({-1: pd.NA})\n",
    "    data[\"bank_balance\"] = pd.to_numeric(data['bank_balance'].astype(str).str.strip()\n",
    "                                        .str.replace(r'[^0-9.]','',regex=True).str.replace(r'(\\.\\d*)\\..*',r'\\1',regex=True),\n",
    "                                        errors=\"coerce\")\n",
    "    data['existing_loans'] = data['existing_loans'].astype(str).str.strip().str.lower()\n",
    "    data['existing_loans'] = data['existing_loans'].replace(r'^\\s*$', pd.NA, regex=True).map({'no':0,'yes':1})\n",
    "    data[\"emi_eligibility\"] = pd.Series(pd.Categorical(data[\"emi_eligibility\"], categories=emi_eligibility_categories, ordered=True).codes).replace({-1: pd.NA})\n",
    "    data = pd.get_dummies(data, columns=[\"emi_scenario\"], dtype=\"int\")\n",
    "    data = data.dropna()\n",
    "    return data\n",
    "\n",
    "# ================== 2ï¸âƒ£ Feature Engineering ==================\n",
    "def feature_engineering(data):\n",
    "    data['debt_to_income'] = data['current_emi_amount'] / data['monthly_salary']\n",
    "    data['expense_to_income'] = (data['school_fees'] + data['college_fees'] + data['travel_expenses'] + \n",
    "                                 data['groceries_utilities'] + data['other_monthly_expenses']) / data['monthly_salary']\n",
    "    data['affordability_ratio'] = (data['monthly_salary'] - data['current_emi_amount'] - \n",
    "                                   data['monthly_rent'] - data['other_monthly_expenses']) / data['requested_amount']\n",
    "    return data\n",
    "\n",
    "# ================== 3ï¸âƒ£ Detect Features ==================\n",
    "def detect_features(data, target_cols=['emi_eligibility','max_monthly_emi']):\n",
    "    return [col for col in data.columns if col not in target_cols]\n",
    "\n",
    "# ================== 4ï¸âƒ£ Split & Scale ==================\n",
    "def split_and_scale_data(data):\n",
    "    X = data.drop(['emi_eligibility', 'max_monthly_emi'], axis=1)\n",
    "    y_class = data['emi_eligibility']\n",
    "    y_reg = data['max_monthly_emi']\n",
    "    X_train, X_temp, y_class_train, y_class_temp, y_reg_train, y_reg_temp = train_test_split(\n",
    "        X, y_class, y_reg, test_size=0.3, random_state=42, stratify=y_class)\n",
    "    X_val, X_test, y_class_val, y_class_test, y_reg_val, y_reg_test = train_test_split(\n",
    "        X_temp, y_class_temp, y_reg_temp, test_size=0.5, random_state=42, stratify=y_class_temp)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train,X_val,X_test,y_class_train,y_class_val,y_class_test,y_reg_train,y_reg_val,y_reg_test,scaler\n",
    "\n",
    "# ================== 5ï¸âƒ£ EDA ==================\n",
    "def exploratory_data_analysis(data):\n",
    "    st.subheader(\"Dataset Overview\")\n",
    "    st.dataframe(data.head())\n",
    "    st.subheader(\"Statistical Summary\")\n",
    "    st.dataframe(data.describe().T)\n",
    "    st.subheader(\"EMI Eligibility Distribution\")\n",
    "    st.bar_chart(data['emi_eligibility'].value_counts())\n",
    "    st.subheader(\"Correlation Heatmap\")\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "    sns.heatmap(data.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\", ax=ax)\n",
    "    st.pyplot(fig)\n",
    "\n",
    "# ================== 6ï¸âƒ£ MLflow Logging ==================\n",
    "def log_classification_mlflow(model_name, model, X_train, X_val, y_train, y_val):\n",
    "    with mlflow.start_run(run_name=f\"{model_name}_Classification\"):\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        f1 = f1_score(y_val, preds, average='weighted')\n",
    "        mlflow.log_params(model.get_params())\n",
    "        mlflow.log_metric(\"F1_weighted\", f1)\n",
    "        mlflow.sklearn.log_model(model, artifact_path=model_name, input_example=X_val[:2], signature=infer_signature(X_val,preds))\n",
    "    return f1\n",
    "\n",
    "def log_regression_mlflow(model_name, model, X_train, X_val, y_train, y_val):\n",
    "    with mlflow.start_run(run_name=f\"{model_name}_Regression\"):\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        r2 = r2_score(y_val, preds)\n",
    "        mlflow.log_params(model.get_params())\n",
    "        mlflow.log_metric(\"R2\", r2)\n",
    "        mlflow.sklearn.log_model(model, artifact_path=model_name, input_example=X_val[:2], signature=infer_signature(X_val,preds))\n",
    "    return r2\n",
    "\n",
    "# ================== 7ï¸âƒ£ Full Pipeline Wrapper ==================\n",
    "def run_full_emi_pipeline(file_path):\n",
    "    # Load & clean\n",
    "    data = load_and_clean_data(file_path)\n",
    "    data = feature_engineering(data)\n",
    "    feature_names = detect_features(data)\n",
    "    \n",
    "    # ML Prep\n",
    "    X_train,X_val,X_test,y_class_train,y_class_val,y_class_test,y_reg_train,y_reg_val,y_reg_test,scaler = split_and_scale_data(data)\n",
    "    mlflow.set_experiment(\"EMI_Prediction_Experiment\")\n",
    "    \n",
    "    # Classification\n",
    "    classifiers = {\n",
    "        \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "        \"RandomForestClassifier\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"XGBoostClassifier\": XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "    }\n",
    "    best_clf, best_clf_score, best_clf_name = None, -1, \"\"\n",
    "    for name, model in classifiers.items():\n",
    "        score = log_classification_mlflow(name, model, X_train, X_val, y_class_train, y_class_val)\n",
    "        if score > best_clf_score:\n",
    "            best_clf_score = score\n",
    "            best_clf = model\n",
    "            best_clf_name = name\n",
    "    \n",
    "    # Regression\n",
    "    regressors = {\n",
    "        \"LinearRegression\": LinearRegression(),\n",
    "        \"RandomForestRegressor\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        \"XGBoostRegressor\": XGBRegressor(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "    }\n",
    "    best_reg, best_reg_score, best_reg_name = None, -float('inf'), \"\"\n",
    "    for name, model in regressors.items():\n",
    "        score = log_regression_mlflow(name, model, X_train, X_val, y_reg_train, y_reg_val)\n",
    "        if score > best_reg_score:\n",
    "            best_reg_score = score\n",
    "            best_reg = model\n",
    "            best_reg_name = name\n",
    "    \n",
    "    # Save models\n",
    "    clf_model_path = f\"best_classifier_{best_clf_name}.pkl\"\n",
    "    reg_model_path = f\"best_regressor_{best_reg_name}.pkl\"\n",
    "    joblib.dump(best_clf, clf_model_path)\n",
    "    joblib.dump(best_reg, reg_model_path)\n",
    "    \n",
    "    # Launch Streamlit\n",
    "    run_emi_streamlit_app_interactive(clf_model_path, reg_model_path, feature_names)\n",
    "\n",
    "# ================== 8ï¸âƒ£ Interactive Streamlit ==================\n",
    "def run_emi_streamlit_app_interactive(classifier_model_path, regressor_model_path, feature_names):\n",
    "    clf_model = joblib.load(classifier_model_path)\n",
    "    reg_model = joblib.load(regressor_model_path)\n",
    "    st.set_page_config(page_title=\"EMI Prediction Dashboard\", layout=\"wide\")\n",
    "    st.title(\"EMI Prediction Platform\")\n",
    "    \n",
    "    uploaded_file = st.file_uploader(\"Upload EMI dataset CSV\", type=\"csv\")\n",
    "    if uploaded_file:\n",
    "        data = pd.read_csv(uploaded_file)\n",
    "        data = feature_engineering(data)\n",
    "        exploratory_data_analysis(data)\n",
    "        st.subheader(\"Predictions\")\n",
    "        preds_class = clf_model.predict(data[feature_names])\n",
    "        preds_reg = reg_model.predict(data[feature_names])\n",
    "        data[\"EMI_Eligibility_Pred\"] = preds_class\n",
    "        data[\"Max_EMI_Pred\"] = preds_reg\n",
    "        st.dataframe(data[['EMI_Eligibility_Pred','Max_EMI_Pred']].head())\n",
    "        st.success(\"Predictions completed successfully!\")\n",
    "\n",
    "# ================== 9ï¸âƒ£ Main ==================\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"emi_prediction_dataset.csv\"  # change to your dataset path\n",
    "    run_full_emi_pipeline(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8542c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamlit run emi_full_pipeline_allinone.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc98720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
